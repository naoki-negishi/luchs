# I/O
  train_data_path: "/code/data/snli_1.0/snli_1.0_train.jsonl"
  dev_data_path: "/code/data/snli_1.0/snli_1.0_dev.jsonl"
  output_dir: "/code/outputs/BaseCLS"

# wandb config
  wandb_proj: "NLIProject"
  wandb_proj_name: "BaseCLS"

# hyper-parameters
  seed: 42
  num_train_epochs: 30
  early_stopping: 10
  per_gpu_train_batch_size: 16
  per_gpu_eval_batch_size: 64
  gradient_accumulation_steps: 16
  learning_rate: 1e-4

# model specific parameters
  tokenize_model: "roberta-base"
  base_model: "roberta-base"
  model_type: 'Baseline-CLS'
